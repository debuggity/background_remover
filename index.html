<!DOCTYPE html>
<html>
<head>
    <title>Background Removal with U2Net</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin-top: 50px;
        }
        #canvas {
            margin-top: 20px;
            border: 1px solid black;
        }
        .controls {
            margin-top: 20px;
        }
        #selected-image {
            display: none;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
</head>
<body>
    <h1>Image Background Removal with U2Net</h1>
    <input id="image-selector" type="file" accept="image/*" style="margin-top:20px;">
    <button id="predict-button" style="margin-top:20px;">Remove Background</button>
    <br>
    <img id="selected-image" src="" />
    <canvas id="canvas" width="320" height="320"></canvas>

    <script>
        document.getElementById("image-selector").addEventListener("change", function() {
            let reader = new FileReader();
            reader.onload = function() {
                let dataURL = reader.result;
                document.getElementById("selected-image").src = dataURL;
            }
            let file = document.getElementById("image-selector").files[0];
            reader.readAsDataURL(file);
        });

        document.getElementById("predict-button").addEventListener("click", async function() {
            const canvas = document.getElementById("canvas");
            const ctx = canvas.getContext("2d");

            // Load the U2Net model
            const session = await ort.InferenceSession.create('./u2netp.onnx');
            console.log("Model loaded");

            let image = document.getElementById("selected-image");
            let offscreenCanvas = document.createElement('canvas');
            let offscreenCtx = offscreenCanvas.getContext('2d');
            offscreenCanvas.width = 320;
            offscreenCanvas.height = 320;
            offscreenCtx.drawImage(image, 0, 0, 320, 320);

            // Get image data and convert to tensor
            let imageData = offscreenCtx.getImageData(0, 0, 320, 320);
            let tensorData = new Float32Array(1 * 3 * 320 * 320);

            for (let i = 0; i < imageData.data.length; i += 4) {
                tensorData[i / 4] = imageData.data[i] / 255; // Red
                tensorData[(i / 4) + (320 * 320)] = imageData.data[i + 1] / 255; // Green
                tensorData[(i / 4) + (2 * 320 * 320)] = imageData.data[i + 2] / 255; // Blue
            }

            const input = new ort.Tensor('float32', tensorData, [1, 3, 320, 320]);
            const feeds = { 'input.1': input };
            const results = await session.run(feeds);

            // Log available output keys
            console.log('Model output keys:', Object.keys(results));

            // Assuming first key is correct
            const outputKey = Object.keys(results)[0];
            const output = results[outputKey];

            let maskData = output.data;
            let maskCanvas = document.createElement('canvas');
            let maskCtx = maskCanvas.getContext('2d');
            maskCanvas.width = 320;
            maskCanvas.height = 320;

            // Apply the mask to the image
            let outputImageData = ctx.createImageData(320, 320);
            for (let i = 0; i < maskData.length; i++) {
                let pixelIndex = i * 4;
                outputImageData.data[pixelIndex] = 0; // Red
                outputImageData.data[pixelIndex + 1] = 0; // Green
                outputImageData.data[pixelIndex + 2] = 0; // Blue
                outputImageData.data[pixelIndex + 3] = Math.round(maskData[i] * 255); // Alpha
            }

            ctx.putImageData(outputImageData, 0, 0);
        });
    </script>
</body>
</html>
